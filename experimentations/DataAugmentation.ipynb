{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install nlpaug"
      ],
      "metadata": {
        "id": "5KWCcVTivKsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nlpaug.augmenter.word as naw\n",
        "import torch"
      ],
      "metadata": {
        "id": "nz2GCsVE5IQA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "collapsed": true,
        "outputId": "529dc220-0f48-4695-f4ad-d337a32231bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'nlpaug'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-682c2bcc8cb5>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnlpaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmenter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnaw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nlpaug'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch data\n",
        "train_data = pd.read_json(\"https://raw.githubusercontent.com/google-research-datasets/Disfl-QA/main/train.json\", orient='index')\n",
        "val_data = pd.read_json(\"https://raw.githubusercontent.com/google-research-datasets/Disfl-QA/main/dev.json\", orient='index')\n",
        "test_data = pd.read_json(\"https://raw.githubusercontent.com/google-research-datasets/Disfl-QA/main/test.json\", orient='index')\n",
        "\n",
        "\n",
        "#clean data\n",
        "train_data = train_data[(train_data['disfluent'].str.len() >= 25)]\n",
        "val_data = val_data[(val_data['disfluent'].str.len() >= 25)]\n",
        "test_data = test_data[(test_data['disfluent'].str.len() >= 25)]\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWuQMh5M5ERR",
        "outputId": "1b4be9fe-f7d4-4af5-9cc1-241fa9c37c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DisfluencyDataset:\n",
        "    def __init__(self, df, col):\n",
        "        self.df = df\n",
        "        self.col = col\n",
        "\n",
        "    def add_noise(self, batch_size=512):\n",
        "      translator = naw.BackTranslationAug(from_model_name='Helsinki-NLP/opus-mt-en-fr',\n",
        "                             to_model_name='Helsinki-NLP/opus-mt-fr-en', device=device)\n",
        "      filler = naw.ContextualWordEmbsAug(action='insert', model_path='bert-base-uncased', device=device)\n",
        "\n",
        "      self.df = self.df.drop(columns=['disfluent'])\n",
        "\n",
        "\n",
        "      # Process sentences in batches\n",
        "      disfluent_sentences = []\n",
        "\n",
        "      for i in range(0, len(self.df), batch_size):\n",
        "        batch = self.df[self.col].iloc[i:i+batch_size].tolist()\n",
        "\n",
        "        # Apply backtranslation and then filler insertion on the batch\n",
        "        batch_translated = translator.augment(batch)\n",
        "        batch_filler = filler.augment(batch_translated)\n",
        "\n",
        "        disfluent_sentences.extend(batch_filler)\n",
        "\n",
        "\n",
        "        # Create the new 'disfluent' column\n",
        "      self.df['disfluent'] = disfluent_sentences\n",
        "      return self.df\n"
      ],
      "metadata": {
        "id": "elM1Vbob6Y5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "navjt0ALFPXx",
        "outputId": "9f6a147f-80d1-4e42-d490-1eb7f0c84979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvVZB2YpYcy",
        "outputId": "877afd6f-1a07-46b5-8a39-8d4f02f19b6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        }
      ],
      "source": [
        "# Initialize the DisfluencyDataset class with the DataFrame and the 'original' column\n",
        "disfluency = DisfluencyDataset(train_data, 'original')\n",
        "train_augmented = disfluency.add_noise(batch_size=256)\n",
        "train_augmented = pd.concat([train_data, train_augmented])\n",
        "\n",
        "disfluency = DisfluencyDataset(test_data, 'original')\n",
        "test_augmented = disfluency.add_noise(batch_size=512)\n",
        "test_augmented = pd.concat([test_data, test_augmented])\n",
        "\n",
        "disfluency = DisfluencyDataset(val_data, 'original')\n",
        "val_augmented = disfluency.add_noise(batch_size=512)\n",
        "val_augmented = pd.concat([val_data, val_augmented])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/'\n",
        "\n",
        "train_augmented.to_csv(f'{output_path}train_augmeneted.csv', index=False)\n",
        "test_augmented.to_csv(f'{output_path}test_augmeneted.csv', index=False)\n",
        "val_augmented.to_csv(f'{output_path}val_augmeneted.csv', index=False)\n"
      ],
      "metadata": {
        "id": "dMkC-6yfNAXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_augmented.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny5VYOtWOYpQ",
        "outputId": "b63dda88-eade-489a-cd87-84ba555924bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14292 entries, 0 to 14291\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   original   14292 non-null  object\n",
            " 1   disfluent  14292 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 223.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_augmented.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkB5nfTuOiaQ",
        "outputId": "9ad231f9-33a5-44a0-f354-9144eeb120c4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7258 entries, 0 to 7257\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   original   7258 non-null   object\n",
            " 1   disfluent  7258 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 113.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_augmented.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QJ2NiKrOn-Y",
        "outputId": "37d9b87f-aef8-484b-c64c-57a2802e3e9e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1990 entries, 0 to 1989\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   original   1990 non-null   object\n",
            " 1   disfluent  1990 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 31.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hq1FiC2jOqen"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}